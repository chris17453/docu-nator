--- ./_temp/summarize.py
+++ ./src/summarize.py
@@ -4,6 +4,19 @@
 
 class summarize:
     def __init__(self,model_dir=None):
+        """Args:
+            model_dir (str, optional): Path to the directory containing the pre-trained model. Defaults to None.
+        
+        Returns:
+            None. Initializes the AutoTokenizer and AutoModelForCausalLM objects.
+        
+        Raises:
+            FileNotFoundError: If the model directory does not exist.
+        
+        Notes:
+            If the pad_token is not explicitly set in the tokenizer, it will be set to the end-of-sentence token.
+            The model will be moved to the CUDA device if available.
+        """
         self.tokenizer = AutoTokenizer.from_pretrained(model_dir)
         self.model = AutoModelForCausalLM.from_pretrained(model_dir, trust_remote_code=True,  torch_dtype="auto",)
         self.model.cuda()
@@ -13,6 +26,20 @@
             self.model.config.pad_token_id = self.tokenizer.eos_token_id
 
     def generate(self, code, attempts=3):
+        """Args:
+            code (str): The code of the function you want to document.
+            attempts (int, optional): The number of attempts to generate a docstring. Default is 3.
+        
+        Returns:
+            str: A valid docstring for the given function.
+        
+        Raises:
+            None
+        
+        Notes:
+            This function uses a language model to generate a docstring based on a given code snippet. It attempts to generate a docstring multiple times,
+            and returns the first valid one it generates.
+        """
         # Required sections
         required_sections = ["Args:", "Returns:", "Raises:", "Notes:"]
 
